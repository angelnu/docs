{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 Welcome to the documentation for k8s@home which aims to support running Kubernetes at home. Features \u00b6 Provide Helm charts to help define, install, and upgrade even the most complex applications in Kubernetes. Provide container images that support Semantic Versioning , multiple architectures, and designed to run in a Kubernetes cluster. Provide community support for people wanting to learn and deploy Kubernetes in their homes. Awesome Home Kubernetes \u00b6 Checkout our curation of projects and resources involving running Kubernetes at home. License \u00b6 This project is licensed under the terms of the Apache 2.0 License license.","title":"Home"},{"location":"#welcome","text":"Welcome to the documentation for k8s@home which aims to support running Kubernetes at home.","title":"Welcome"},{"location":"#features","text":"Provide Helm charts to help define, install, and upgrade even the most complex applications in Kubernetes. Provide container images that support Semantic Versioning , multiple architectures, and designed to run in a Kubernetes cluster. Provide community support for people wanting to learn and deploy Kubernetes in their homes.","title":"Features"},{"location":"#awesome-home-kubernetes","text":"Checkout our curation of projects and resources involving running Kubernetes at home.","title":"Awesome Home Kubernetes"},{"location":"#license","text":"This project is licensed under the terms of the Apache 2.0 License license.","title":"License"},{"location":"guides/dyndns/","text":"Introduction \u00b6 This is a guide on how to use native k8s CronJob s to sync your WAN IP to a dns provider. Creating a ConfigMap \u00b6 Let's get started by creating a configmap with the script to update to your DNS provider. Note In this example we will be using DigitalOcean This can work with any provider as long as your script works A quick search yielded this gist . Let's go ahead and update it a bit to work in our CronJob while putting it in a configmap . # configmap.yaml --- apiVersion : v1 kind : ConfigMap metadata : name : dyndns-updater namespace : default labels : app.kubernetes.io/name : dyndns-updater app.kubernetes.io/instance : dyndns-updater data : dyndns-updater.sh : | #!/bin/sh # Get your WAN IP IP=$(curl -s checkip.dyndns.org | grep -Eo '[0-9\\.]+') # Get the Record ID associated with the $DOMAIN RECORD_ID=$(curl -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer ${TOKEN}\" \"https://api.digitalocean.com/v2/domains/${DOMAIN}/records\") # Send request to update DNS Record curl -s -X PUT \\ -H \"Content-Type: application/json\" \\ -H \"Authorization: Bearer $TOKEN\" \\ -d \"{\\\"data\\\":\\\"${IP}\\\"}\" \\ \"https://api.digitalocean.com/v2/domains/${DOMAIN}/records/${RECORD_ID}\" Creating a Secret \u00b6 Next step is to create a secret, this will require a $TOKEN passed thru to the CronJob . # secret.yaml --- apiVersion : v1 kind : Secret metadata : name : do-token namespace : default type : Opaque data : # Your domain name in base64 DOMAIN : fWataR3= # You API token in base64 # Get token from https://cloud.digitalocean.com/settings/applications TOKEN : YWRtaW4= Creating the CronJob \u00b6 Last step is to put it altogether is creating the CronJob . This will run every hour, on the hour. Tweak the cron formula as needed. # cronjob.yaml --- apiVersion : batch/v1beta1 kind : CronJob metadata : namespace : default name : dyndns-updater spec : schedule : \"0 * * * *\" failedJobsHistoryLimit : 1 successfulJobsHistoryLimit : 3 concurrencyPolicy : Forbid jobTemplate : spec : template : spec : restartPolicy : Never containers : - name : dyndns-updater image : curlimages/curl:7.75.0 imagePullPolicy : IfNotPresent envFrom : - secretRef : name : do-token command : - \"/bin/sh\" - \"-ec\" - \"/app/dyndns-updater.sh\" volumeMounts : - name : dyndns-updater mountPath : /app/dyndns-updater.sh subPath : dyndns-updater.sh readOnly : true volumes : - name : dyndns-updater projected : defaultMode : 0775 sources : - configMap : name : dyndns-updater items : - key : dyndns-updater.sh path : dyndns-updater.sh","title":"DynDNS with a CronJob"},{"location":"guides/dyndns/#introduction","text":"This is a guide on how to use native k8s CronJob s to sync your WAN IP to a dns provider.","title":"Introduction"},{"location":"guides/dyndns/#creating-a-configmap","text":"Let's get started by creating a configmap with the script to update to your DNS provider. Note In this example we will be using DigitalOcean This can work with any provider as long as your script works A quick search yielded this gist . Let's go ahead and update it a bit to work in our CronJob while putting it in a configmap . # configmap.yaml --- apiVersion : v1 kind : ConfigMap metadata : name : dyndns-updater namespace : default labels : app.kubernetes.io/name : dyndns-updater app.kubernetes.io/instance : dyndns-updater data : dyndns-updater.sh : | #!/bin/sh # Get your WAN IP IP=$(curl -s checkip.dyndns.org | grep -Eo '[0-9\\.]+') # Get the Record ID associated with the $DOMAIN RECORD_ID=$(curl -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer ${TOKEN}\" \"https://api.digitalocean.com/v2/domains/${DOMAIN}/records\") # Send request to update DNS Record curl -s -X PUT \\ -H \"Content-Type: application/json\" \\ -H \"Authorization: Bearer $TOKEN\" \\ -d \"{\\\"data\\\":\\\"${IP}\\\"}\" \\ \"https://api.digitalocean.com/v2/domains/${DOMAIN}/records/${RECORD_ID}\"","title":"Creating a ConfigMap"},{"location":"guides/dyndns/#creating-a-secret","text":"Next step is to create a secret, this will require a $TOKEN passed thru to the CronJob . # secret.yaml --- apiVersion : v1 kind : Secret metadata : name : do-token namespace : default type : Opaque data : # Your domain name in base64 DOMAIN : fWataR3= # You API token in base64 # Get token from https://cloud.digitalocean.com/settings/applications TOKEN : YWRtaW4=","title":"Creating a Secret"},{"location":"guides/dyndns/#creating-the-cronjob","text":"Last step is to put it altogether is creating the CronJob . This will run every hour, on the hour. Tweak the cron formula as needed. # cronjob.yaml --- apiVersion : batch/v1beta1 kind : CronJob metadata : namespace : default name : dyndns-updater spec : schedule : \"0 * * * *\" failedJobsHistoryLimit : 1 successfulJobsHistoryLimit : 3 concurrencyPolicy : Forbid jobTemplate : spec : template : spec : restartPolicy : Never containers : - name : dyndns-updater image : curlimages/curl:7.75.0 imagePullPolicy : IfNotPresent envFrom : - secretRef : name : do-token command : - \"/bin/sh\" - \"-ec\" - \"/app/dyndns-updater.sh\" volumeMounts : - name : dyndns-updater mountPath : /app/dyndns-updater.sh subPath : dyndns-updater.sh readOnly : true volumes : - name : dyndns-updater projected : defaultMode : 0775 sources : - configMap : name : dyndns-updater items : - key : dyndns-updater.sh path : dyndns-updater.sh","title":"Creating the CronJob"},{"location":"our-container-images/configuration/","text":"Configuration \u00b6 The following configuration is available across all the k8s@home container images. Environment Variables \u00b6 Name Default Description UMASK 0002 Set the default creation permission mode of files WAIT_FOR_VPN false EXTRA_ARGS Additional arguments to pass to the application TZ UTC Timezone (e.g. America/New_York ) Volumes \u00b6 Path Description /app Application install directory /config Application configuration directory User \u00b6 User ID kah 568","title":"Configuration"},{"location":"our-container-images/configuration/#configuration","text":"The following configuration is available across all the k8s@home container images.","title":"Configuration"},{"location":"our-container-images/configuration/#environment-variables","text":"Name Default Description UMASK 0002 Set the default creation permission mode of files WAIT_FOR_VPN false EXTRA_ARGS Additional arguments to pass to the application TZ UTC Timezone (e.g. America/New_York )","title":"Environment Variables"},{"location":"our-container-images/configuration/#volumes","text":"Path Description /app Application install directory /config Application configuration directory","title":"Volumes"},{"location":"our-container-images/configuration/#user","text":"User ID kah 568","title":"User"},{"location":"our-container-images/introduction/","text":"Introduction \u00b6 Running applications in Kubernetes is a bit different that in a regular Docker Swarm or Docker Compose setup. Our container images are tailored for running in Kubernetes. Purpose \u00b6 The goal of this project and the container images are to support Semantic Versioning and multiple architectures. We try to keep a KISS principle when building these images, which means no s6-overlay and all images are built on top of ubuntu:focal . Deprecations \u00b6 Container images that were once here but now are gone it is likely that the application... developers are supporting their own images and conforming to Semantic Versioning , or has been replaced with a different application, or maintenance cost it too high to continue to build images for, or is no longer maintained","title":"Introduction"},{"location":"our-container-images/introduction/#introduction","text":"Running applications in Kubernetes is a bit different that in a regular Docker Swarm or Docker Compose setup. Our container images are tailored for running in Kubernetes.","title":"Introduction"},{"location":"our-container-images/introduction/#purpose","text":"The goal of this project and the container images are to support Semantic Versioning and multiple architectures. We try to keep a KISS principle when building these images, which means no s6-overlay and all images are built on top of ubuntu:focal .","title":"Purpose"},{"location":"our-container-images/introduction/#deprecations","text":"Container images that were once here but now are gone it is likely that the application... developers are supporting their own images and conforming to Semantic Versioning , or has been replaced with a different application, or maintenance cost it too high to continue to build images for, or is no longer maintained","title":"Deprecations"},{"location":"our-container-images/permissions/","text":"Permissions \u00b6 With Kubernetes, s6-overlay is not needed. Instead Kubernetes can use Security Context on either the pod or container to tell what the container should run as, and/or what permissions files should be written as. Managing Permissions \u00b6 There are several different methods you can use to make these containers have write access to your file storage. Note Our images use a default user/group id of 568 . The user and group ids cannot be changed at the container runtime. Security Contexts method \u00b6 You can change the Kubernetes Security Contexts to allow the container to have permissions to write to your file storage. In our Helm charts this can be accomplished by setting the following option in you Helm values. Note According to the Kubernetes docs fsGroup will chown the volume with the runAsUser and runAsGroup IDs. As such this option should only have to be set once or it may cause your pod to take long to start each time it is started. podSecurityContext : runAsUser : 568 runAsGroup : 568 fsGroup : 568 initContainer method \u00b6 Implement a initContainer that runs as root to automatically chown the volume's data. initContainers : - name : update-volume-permission image : busybox command : [ \"sh\" , \"-c\" , \"chown -R 568:568 /config\" ] volumeMounts : - name : config mountPath : /config securityContext : runAsUser : 0 Direct volume method \u00b6 Warning This step can be a bit complicated if you are not very familiar with your storage interface. If you can mount the volume's config without the pod running. You can run chown -R 568:568 <path-to-the mounted-volume-on-the host> . As this method varies greatly depending on your CSI driver, we won't be mentioning how to accomplish this.","title":"Permissions"},{"location":"our-container-images/permissions/#permissions","text":"With Kubernetes, s6-overlay is not needed. Instead Kubernetes can use Security Context on either the pod or container to tell what the container should run as, and/or what permissions files should be written as.","title":"Permissions"},{"location":"our-container-images/permissions/#managing-permissions","text":"There are several different methods you can use to make these containers have write access to your file storage. Note Our images use a default user/group id of 568 . The user and group ids cannot be changed at the container runtime.","title":"Managing Permissions"},{"location":"our-container-images/permissions/#security-contexts-method","text":"You can change the Kubernetes Security Contexts to allow the container to have permissions to write to your file storage. In our Helm charts this can be accomplished by setting the following option in you Helm values. Note According to the Kubernetes docs fsGroup will chown the volume with the runAsUser and runAsGroup IDs. As such this option should only have to be set once or it may cause your pod to take long to start each time it is started. podSecurityContext : runAsUser : 568 runAsGroup : 568 fsGroup : 568","title":"Security Contexts method"},{"location":"our-container-images/permissions/#initcontainer-method","text":"Implement a initContainer that runs as root to automatically chown the volume's data. initContainers : - name : update-volume-permission image : busybox command : [ \"sh\" , \"-c\" , \"chown -R 568:568 /config\" ] volumeMounts : - name : config mountPath : /config securityContext : runAsUser : 0","title":"initContainer method"},{"location":"our-container-images/permissions/#direct-volume-method","text":"Warning This step can be a bit complicated if you are not very familiar with your storage interface. If you can mount the volume's config without the pod running. You can run chown -R 568:568 <path-to-the mounted-volume-on-the host> . As this method varies greatly depending on your CSI driver, we won't be mentioning how to accomplish this.","title":"Direct volume method"},{"location":"our-container-images/development/base-images/","text":"Base images \u00b6 The k8s@home base images are meant to be used as an image to build all other app container images on top of. Distributions \u00b6 The following distributions are available as a base image: Ubuntu Alpine The source code can be found here . shim scripts \u00b6 shim scripts have been added to the Ubuntu base image to perform startup tasks before the app is launched. Note The shim scripts must be sourced in the entrypoint.sh file in order to work. config.sh \u00b6 The config.sh shim script is used to create the /config folder. umask.sh \u00b6 The umask.sh shim script is used to set the setting of a mask that controls how file permissions are set for newly created files. vpn.sh \u00b6 The vpn.sh shim script is used to allow the container to wait for the VPN connection before running the app. Tini \u00b6 The base images use the Tini init in order to create the smallest image possible while still waiting for a child to exit all the while reaping zombies and performing signal forwarding.","title":"Base images"},{"location":"our-container-images/development/base-images/#base-images","text":"The k8s@home base images are meant to be used as an image to build all other app container images on top of.","title":"Base images"},{"location":"our-container-images/development/base-images/#distributions","text":"The following distributions are available as a base image: Ubuntu Alpine The source code can be found here .","title":"Distributions"},{"location":"our-container-images/development/base-images/#shim-scripts","text":"shim scripts have been added to the Ubuntu base image to perform startup tasks before the app is launched. Note The shim scripts must be sourced in the entrypoint.sh file in order to work.","title":"shim scripts"},{"location":"our-container-images/development/base-images/#configsh","text":"The config.sh shim script is used to create the /config folder.","title":"config.sh"},{"location":"our-container-images/development/base-images/#umasksh","text":"The umask.sh shim script is used to set the setting of a mask that controls how file permissions are set for newly created files.","title":"umask.sh"},{"location":"our-container-images/development/base-images/#vpnsh","text":"The vpn.sh shim script is used to allow the container to wait for the VPN connection before running the app.","title":"vpn.sh"},{"location":"our-container-images/development/base-images/#tini","text":"The base images use the Tini init in order to create the smallest image possible while still waiting for a child to exit all the while reaping zombies and performing signal forwarding.","title":"Tini"},{"location":"our-container-images/development/build/","text":"Build \u00b6 Building of the container images need to be done from the root directory of the repository so that the app files, such as entrypoint.sh , can be properly copied into the image. Docker Buildx \u00b6 Docker Buildx is required to build multi-platform images. qemu-user-static may be used to enable an execution of different multi-architecture containers by QEMU and binfmt_misc. docker run --rm --privileged multiarch/qemu-user-static --reset -p yes Task \u00b6 Task may be used to semi-automate the building and loading of a container image. The APP parameter will need to be set in order to tell Task which app needs to be processed. Run the following command from the root directory of the repository. task build APP = <app name> Other tasks can be listed by running task -l . Manual \u00b6 The container images can be built and loaded manually by using the Docker cli from the repository root directory. Build \u00b6 docker buildx build --build-arg VERSION = $( cat ./apps/<app name>/VERSION ) --platform $( cat ./apps/<app name>/PLATFORM ) -f ./apps/<app name>/Dockerfile . Load \u00b6 docker buildx build -t <app name>:test --build-arg VERSION = $( cat ./apps/<app name>/VERSION ) -f ./apps/<app name>/Dockerfile . --load","title":"Build"},{"location":"our-container-images/development/build/#build","text":"Building of the container images need to be done from the root directory of the repository so that the app files, such as entrypoint.sh , can be properly copied into the image.","title":"Build"},{"location":"our-container-images/development/build/#docker-buildx","text":"Docker Buildx is required to build multi-platform images. qemu-user-static may be used to enable an execution of different multi-architecture containers by QEMU and binfmt_misc. docker run --rm --privileged multiarch/qemu-user-static --reset -p yes","title":"Docker Buildx"},{"location":"our-container-images/development/build/#task","text":"Task may be used to semi-automate the building and loading of a container image. The APP parameter will need to be set in order to tell Task which app needs to be processed. Run the following command from the root directory of the repository. task build APP = <app name> Other tasks can be listed by running task -l .","title":"Task"},{"location":"our-container-images/development/build/#manual","text":"The container images can be built and loaded manually by using the Docker cli from the repository root directory.","title":"Manual"},{"location":"our-container-images/development/build/#build_1","text":"docker buildx build --build-arg VERSION = $( cat ./apps/<app name>/VERSION ) --platform $( cat ./apps/<app name>/PLATFORM ) -f ./apps/<app name>/Dockerfile .","title":"Build"},{"location":"our-container-images/development/build/#load","text":"docker buildx build -t <app name>:test --build-arg VERSION = $( cat ./apps/<app name>/VERSION ) -f ./apps/<app name>/Dockerfile . --load","title":"Load"},{"location":"our-container-images/development/creating-a-new-container-image/","text":"Creating a new container image \u00b6 Dependencies \u00b6 If you would like to help create new container images, there's a few tools you will need: Docker buildx jq goss & dgoss task (optional) Creating a new container image \u00b6 Currently, there isn't a template to start from and so you can either start with an already existing app or you can start from scratch. Create a folder in in the apps folder with the name of the container image. Add the following files to the container image folder. Folder structure \u00b6 apps/app name/ \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 entrypoint.sh \u251c\u2500\u2500 goss.yaml \u251c\u2500\u2500 latest-version.sh \u251c\u2500\u2500 PLATFORM \u251c\u2500\u2500 shim \u2502 \u2514\u2500\u2500 shim-script.sh \u2514\u2500\u2500 VERSION Dockerfile \u00b6 See Dockerfile . PLATFORM \u00b6 The PLATFORM file is used by the Apps - Build, Test, Push github action to build multi-platform container images. At a minimum, the following platforms should be supported by the container image: amd64 arm64 linux/amd64,linux/arm64 VERSION \u00b6 The VERSION file is used by the Apps - Build, Test, Push github action to determine the version of the app with which to build the container image. The VERSION file may be updated manually by running the latest-version.sh script. ./latest-version.sh > VERSION entrypoint.sh \u00b6 The entrypoint.sh file is a standard Docker entrypoint file . This file will most likely be custom for each app. It is recommended to take a look at other container images or other versions of the Docker image for the app. A good source might be searching Docker Hub . The only difference is the sourcing of the base image shim scripts which are added to the base image. #shellcheck disable=SC1091 source \"/shim/umask.sh\" source \"/shim/vpn.sh\" If the app has custom shim scripts , be sure to source those as well. source \"/shim/<app name>-preferences.sh\" goss.yaml \u00b6 The goss.yaml file is used by the Apps - Build, Test, Push github action to perform a health check on the container image using goss . Be sure to update the process name, port number(s) and title . See the manual for more options. --- process : Lidarr : running : true port : tcp6:8686 : listening : true http : http://localhost:8686 : status : 200 body : - '<title>Lidarr</title>' latest-version.sh \u00b6 The latest-version.sh script is used by the Apps - Get latest versions github action to get the latest version of the app. This script is custom for each app and so it will need to be developed for each app. Below is an example of one. #!/usr/bin/env bash # Get the version using jq from the json response. version = $( curl -sX GET \"https://lidarr.servarr.com/v1/update/nightly/changes?os=linux\" | jq --raw-output '.[0].version' ) # Strip the v from the beginning of version if it exists. version = \" ${ version #*v } \" # Remove release and dash from the beginning of version if it exists. version = \" ${ version #*release- } \" # Print the verion without a new line (\\n) character. printf \"%s\" \" ${ version } \" shim scripts \u00b6 Custom startup scripts should be added to the shim folder that needs to be run before the app is started. Create a shim folder in the app name folder then add the shim scripts to the shim folder. Then add following line to the Dockerfile to copy the scripts over to the image. Then be sure to add a source line to the entrypoint.sh script . See plex for reference.","title":"Creating a new container image"},{"location":"our-container-images/development/creating-a-new-container-image/#creating-a-new-container-image","text":"","title":"Creating a new container image"},{"location":"our-container-images/development/creating-a-new-container-image/#dependencies","text":"If you would like to help create new container images, there's a few tools you will need: Docker buildx jq goss & dgoss task (optional)","title":"Dependencies"},{"location":"our-container-images/development/creating-a-new-container-image/#creating-a-new-container-image_1","text":"Currently, there isn't a template to start from and so you can either start with an already existing app or you can start from scratch. Create a folder in in the apps folder with the name of the container image. Add the following files to the container image folder.","title":"Creating a new container image"},{"location":"our-container-images/development/creating-a-new-container-image/#folder-structure","text":"apps/app name/ \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 entrypoint.sh \u251c\u2500\u2500 goss.yaml \u251c\u2500\u2500 latest-version.sh \u251c\u2500\u2500 PLATFORM \u251c\u2500\u2500 shim \u2502 \u2514\u2500\u2500 shim-script.sh \u2514\u2500\u2500 VERSION","title":"Folder structure"},{"location":"our-container-images/development/creating-a-new-container-image/#dockerfile","text":"See Dockerfile .","title":"Dockerfile"},{"location":"our-container-images/development/creating-a-new-container-image/#platform","text":"The PLATFORM file is used by the Apps - Build, Test, Push github action to build multi-platform container images. At a minimum, the following platforms should be supported by the container image: amd64 arm64 linux/amd64,linux/arm64","title":"PLATFORM"},{"location":"our-container-images/development/creating-a-new-container-image/#version","text":"The VERSION file is used by the Apps - Build, Test, Push github action to determine the version of the app with which to build the container image. The VERSION file may be updated manually by running the latest-version.sh script. ./latest-version.sh > VERSION","title":"VERSION"},{"location":"our-container-images/development/creating-a-new-container-image/#entrypointsh","text":"The entrypoint.sh file is a standard Docker entrypoint file . This file will most likely be custom for each app. It is recommended to take a look at other container images or other versions of the Docker image for the app. A good source might be searching Docker Hub . The only difference is the sourcing of the base image shim scripts which are added to the base image. #shellcheck disable=SC1091 source \"/shim/umask.sh\" source \"/shim/vpn.sh\" If the app has custom shim scripts , be sure to source those as well. source \"/shim/<app name>-preferences.sh\"","title":"entrypoint.sh"},{"location":"our-container-images/development/creating-a-new-container-image/#gossyaml","text":"The goss.yaml file is used by the Apps - Build, Test, Push github action to perform a health check on the container image using goss . Be sure to update the process name, port number(s) and title . See the manual for more options. --- process : Lidarr : running : true port : tcp6:8686 : listening : true http : http://localhost:8686 : status : 200 body : - '<title>Lidarr</title>'","title":"goss.yaml"},{"location":"our-container-images/development/creating-a-new-container-image/#latest-versionsh","text":"The latest-version.sh script is used by the Apps - Get latest versions github action to get the latest version of the app. This script is custom for each app and so it will need to be developed for each app. Below is an example of one. #!/usr/bin/env bash # Get the version using jq from the json response. version = $( curl -sX GET \"https://lidarr.servarr.com/v1/update/nightly/changes?os=linux\" | jq --raw-output '.[0].version' ) # Strip the v from the beginning of version if it exists. version = \" ${ version #*v } \" # Remove release and dash from the beginning of version if it exists. version = \" ${ version #*release- } \" # Print the verion without a new line (\\n) character. printf \"%s\" \" ${ version } \"","title":"latest-version.sh"},{"location":"our-container-images/development/creating-a-new-container-image/#shim-scripts","text":"Custom startup scripts should be added to the shim folder that needs to be run before the app is started. Create a shim folder in the app name folder then add the shim scripts to the shim folder. Then add following line to the Dockerfile to copy the scripts over to the image. Then be sure to add a source line to the entrypoint.sh script . See plex for reference.","title":"shim scripts"},{"location":"our-container-images/development/dockerfile/","text":"Dockerfile \u00b6 The Dockerfile file is a standard Dockerfile with a few additions. Base images \u00b6 Be sure to use one of the base k8s@home images for the FROM instruction. Ubuntu \u00b6 # hadolint ignore=DL3007 FROM ghcr.io/k8s-at-home/ubuntu:latest Alpine \u00b6 # hadolint ignore=DL3007 FROM ghcr.io/k8s-at-home/alpine:latest package_info \u00b6 Also, be sure to add the package_info file to the image so that others can find the source of the container image. RUN printf \"UpdateMethod=docker\\nPackageVersion=%s\\nPackageAuthor=[Team k8s-at-home](https://github.com/k8s-at-home)\" \" ${ VERSION } \" > /app/package_info UMASK and ca-certificates \u00b6 Ensure that you change the permissions of the /app folder, set the UMASK environmental variable, and update ca-certificates . RUN \\ chmod -R u = rwX,go = rX /app \\ && printf \"umask %d\" \" ${ UMASK } \" >> /etc/bash.bashrc \\ && update-ca-certificates COPY \u00b6 When using the COPY instruction, be sure to start from the root of the repository so that the github actions can build the container image properly. COPY ./apps/<app name>/entrypoint.sh /entrypoint.sh USER \u00b6 Be sure set the USER to kah . See Configuration for details. USER kah shim scripts \u00b6 If custom shim scripts are used, be sure to copy them to the container image. COPY ./apps/<app name>/shim/<app name>-preferences.sh /shim/<app name>-preferences.sh Linting \u00b6 Hadolint needs to be used to lint the Dockerfile before publishing. Hadolint is also used as a check in the Apps - Build, Test, Push github action hadolint Dockerfile Best practices \u00b6 Be sure to use best practices up for writing Dockerfiles in order to reduce the container image size.","title":"Dockerfile"},{"location":"our-container-images/development/dockerfile/#dockerfile","text":"The Dockerfile file is a standard Dockerfile with a few additions.","title":"Dockerfile"},{"location":"our-container-images/development/dockerfile/#base-images","text":"Be sure to use one of the base k8s@home images for the FROM instruction.","title":"Base images"},{"location":"our-container-images/development/dockerfile/#ubuntu","text":"# hadolint ignore=DL3007 FROM ghcr.io/k8s-at-home/ubuntu:latest","title":"Ubuntu"},{"location":"our-container-images/development/dockerfile/#alpine","text":"# hadolint ignore=DL3007 FROM ghcr.io/k8s-at-home/alpine:latest","title":"Alpine"},{"location":"our-container-images/development/dockerfile/#package_info","text":"Also, be sure to add the package_info file to the image so that others can find the source of the container image. RUN printf \"UpdateMethod=docker\\nPackageVersion=%s\\nPackageAuthor=[Team k8s-at-home](https://github.com/k8s-at-home)\" \" ${ VERSION } \" > /app/package_info","title":"package_info"},{"location":"our-container-images/development/dockerfile/#umask-and-ca-certificates","text":"Ensure that you change the permissions of the /app folder, set the UMASK environmental variable, and update ca-certificates . RUN \\ chmod -R u = rwX,go = rX /app \\ && printf \"umask %d\" \" ${ UMASK } \" >> /etc/bash.bashrc \\ && update-ca-certificates","title":"UMASK and ca-certificates"},{"location":"our-container-images/development/dockerfile/#copy","text":"When using the COPY instruction, be sure to start from the root of the repository so that the github actions can build the container image properly. COPY ./apps/<app name>/entrypoint.sh /entrypoint.sh","title":"COPY"},{"location":"our-container-images/development/dockerfile/#user","text":"Be sure set the USER to kah . See Configuration for details. USER kah","title":"USER"},{"location":"our-container-images/development/dockerfile/#shim-scripts","text":"If custom shim scripts are used, be sure to copy them to the container image. COPY ./apps/<app name>/shim/<app name>-preferences.sh /shim/<app name>-preferences.sh","title":"shim scripts"},{"location":"our-container-images/development/dockerfile/#linting","text":"Hadolint needs to be used to lint the Dockerfile before publishing. Hadolint is also used as a check in the Apps - Build, Test, Push github action hadolint Dockerfile","title":"Linting"},{"location":"our-container-images/development/dockerfile/#best-practices","text":"Be sure to use best practices up for writing Dockerfiles in order to reduce the container image size.","title":"Best practices"},{"location":"our-helm-charts/common-library-add-ons/","text":"Common library add-ons \u00b6 Our Helm charts have a few add-ons which are meant to simplify some features you might be looking for. These are sidecars that run in the same pod as your application you configured it with. Code Server \u00b6 The code-server add-on can be used to access and modify persistent volume data in your application. This can be useful when you need to edit the persistent volume data, for example with Home Assistant. Example values \u00b6 Below is a snippet from a values.yaml using the add-on. More configuration options can be found in our common chart documentation. Note This example will mount /config into the code-server sidecar. addons : codeserver : enabled : true image : repository : codercom/code-server tag : 3.9.0 workingDir : \"/config\" args : - --auth - \"none\" - --user-data-dir - \"/config/.vscode\" - --extensions-dir - \"/config/.vscode\" ingress : enabled : true annotations : kubernetes.io/ingress.class : \"nginx\" hosts : - host : app-config.domain.tld paths : - path : / pathType : Prefix tls : - hosts : - app-config.domain.tld volumeMounts : - name : config mountPath : /config Wireguard VPN \u00b6 The Wireguard add-on enables you to force all (or selected) network traffic through a VPN. This example shows how to add a Wireguard sidecar to our qBittorrent Helm chart . It does not cover all of the configuration possibilities of the Wireguard client image , but should give a good starting point for configuring a similar setup. Example values \u00b6 Below is an annotated example values.yaml that will result in a qBittorrent container with all its traffic routed through a VPN. In order to have functioning ingress and/or probes, it might be required to open certain networks or ports on the VPN firewall. That is beyond the scope of this document. Please refer to the Wireguard client image for more details on these environment variables. Note The WAIT_FOR_VPN environment variable is specifically implemented by our own qBittorrent image, and it will not work with other container images. image : repository : k8sathome/qbittorrent tag : v4.3.3 pullPolicy : IfNotPresent env : # Our qBittorrent image has a feature that can wait for the VPN to be connected before actually starting the application. # It does this by checking the contents of a file /shared/vpnstatus to contain the string 'connected'. WAIT_FOR_VPN : \"true\" persistence : config : enabled : true emptyDir : true mountPath : /config # This should be enabled so that both the qBittorrent and Wireguard container have access to a shared volume mounted to /shared. # It will be used to communicate between the two containers. shared : enabled : true emptyDir : true mountPath : /shared addons : vpn : enabled : true # This Should be set to `wireguard`. This will set the add-on to use the default settings for Wireguard based connections. type : wireguard # If the podSecurityContext is set to run as a different user, make sure to run the Wireguard container as UID/GID 568. # This is required for it to be able to read certain configuration files. securityContext : runAsUser : 568 runAsGroup : 568 env : # Enable a killswitch that kills all trafic when the VPN is not connected KILLSWITCH : \"true\" # The wireguard configuration file provided by your VPN provider goes here. # # Set AllowedIPs to 0.0.0.0/0 to route all traffic through the VPN. # # Pay close attention to the PostUp and PreDown lines. They must be added if you wish to run a script when the connection # is opened / closed. configFile : |- [Interface] PrivateKey = <my-private-key> Address = <interface address> DNS = <interface DNS server> PostUp = /config/up.sh %i PreDown = /config/down.sh %i [Peer] PublicKey = <my-public-key> AllowedIPs = 0.0.0.0/0 Endpoint = <peer endpoint> # The scripts that get run when the VPN connection opens/closes are defined here. # The default scripts will write a string to represent the current connection state to a file. # Our qBittorrent image has a feature that can wait for this file to contain the word 'connected' before actually starting the application. scripts : up : |- #!/bin/bash echo \"connected\" > /shared/vpnstatus down : |- #!/bin/bash echo \"disconnected\" > /shared/vpnstatus OpenVPN \u00b6 Similar to the Wireguard VPN, the OpenVPN add-on enables you to force all (or selected) network traffic through a VPN. This example shows how to add an OpenVPN sidecar to our qBittorrent Helm chart . It does not cover all of the configuration possibilities of the OpenVPN client image by @dperson , but should give a good starting point for configuring a similar setup. Example values \u00b6 Below is an annotated example values.yaml that will result in a qBittorrent container with all its traffic routed through a VPN. In order to have functioning ingress and/or probes, it might be required to open certain networks or ports on the VPN firewall. That is beyond the scope of this document. Please refer to the OpenVPN client image for more details on these environment variables. Note The WAIT_FOR_VPN environment variable is specifically implemented by our own qBittorrent image, and it will not work with other container images. image : repository : k8sathome/qbittorrent tag : v4.3.3 pullPolicy : IfNotPresent env : # Our qBittorrent image has a feature that can wait for the VPN to be # connected before actually starting the application. # It does this by checking the contents of a file /shared/vpnstatus to # contain the string 'connected'. WAIT_FOR_VPN : \"true\" persistence : config : enabled : true emptyDir : true mountPath : /config # This should be enabled so that both the qBittorrent and OpenVPN container have access to a shared volume mounted to /shared. # It will be used to communicate between the two containers. shared : enabled : true emptyDir : true mountPath : /shared addons : vpn : enabled : true # This Should be set to `openvpn`. This will set the add-on to use the default settings for OpenVPN based connections. type : openvpn openvpn : # This gets read by the Helm chart. The default OpenVPN image reads this and uses it to connect to the VPN provider. auth : | myuser mypassword # If the podSecurityContext is set to run as a different user, make sure to run the OpenVPN container as root. # This is required for it to be able to read certain configuration files. securityContext : runAsGroup : 0 runAsUser : 0 env : # Set this environment variable to 'on' to make sure all traffic gets routed through the VPN container. # Make sure to check the other environment variables for the OpenVPN image to see how you can exclude certain # traffic from these firewall rules. FIREWALL : 'on' # The .ovpn file provided by your VPN provider goes here. # # Any CA / certificate must either be placed inline, or provided through an additionalVolumeMount so that OpenVPN can find it. # # Pay close attention to the last 3 lines in this file. They must be added if you wish to run a script when the connection # is opened / closed. configFile : |- client dev tun proto udp remote my-awesome-vpn-provider.com 995 remote-cert-tls server resolv-retry infinite nobind tls-version-min 1.2 cipher AES-128-GCM compress ncp-disable tun-mtu-extra 32 auth-user-pass <ca> -----BEGIN CERTIFICATE----- MIIDMTCCAhmgAwIBAgIJAKnGGJK6qLqSMA0GCSqGSIb3DQEBCwUAMBQxEjAQBgNV -----END CERTIFICATE----- </ca> script-security 2 up /vpn/up.sh down /vpn/down.sh # The scripts that get run when the VPN connection opens/closes are defined here. # The default scripts will write a string to represent the current connection state to a file. # Our qBittorrent image has a feature that can wait for this file to contain the word 'connected' before actually starting the application. scripts : up : |- #!/bin/bash /etc/openvpn/up.sh echo \"connected\" > /shared/vpnstatus down : |- #!/bin/bash /etc/openvpn/down.sh echo \"disconnected\" > /shared/vpnstatus","title":"Common Add-ons"},{"location":"our-helm-charts/common-library-add-ons/#common-library-add-ons","text":"Our Helm charts have a few add-ons which are meant to simplify some features you might be looking for. These are sidecars that run in the same pod as your application you configured it with.","title":"Common library add-ons"},{"location":"our-helm-charts/common-library-add-ons/#code-server","text":"The code-server add-on can be used to access and modify persistent volume data in your application. This can be useful when you need to edit the persistent volume data, for example with Home Assistant.","title":"Code Server"},{"location":"our-helm-charts/common-library-add-ons/#example-values","text":"Below is a snippet from a values.yaml using the add-on. More configuration options can be found in our common chart documentation. Note This example will mount /config into the code-server sidecar. addons : codeserver : enabled : true image : repository : codercom/code-server tag : 3.9.0 workingDir : \"/config\" args : - --auth - \"none\" - --user-data-dir - \"/config/.vscode\" - --extensions-dir - \"/config/.vscode\" ingress : enabled : true annotations : kubernetes.io/ingress.class : \"nginx\" hosts : - host : app-config.domain.tld paths : - path : / pathType : Prefix tls : - hosts : - app-config.domain.tld volumeMounts : - name : config mountPath : /config","title":"Example values"},{"location":"our-helm-charts/common-library-add-ons/#wireguard-vpn","text":"The Wireguard add-on enables you to force all (or selected) network traffic through a VPN. This example shows how to add a Wireguard sidecar to our qBittorrent Helm chart . It does not cover all of the configuration possibilities of the Wireguard client image , but should give a good starting point for configuring a similar setup.","title":"Wireguard VPN"},{"location":"our-helm-charts/common-library-add-ons/#example-values_1","text":"Below is an annotated example values.yaml that will result in a qBittorrent container with all its traffic routed through a VPN. In order to have functioning ingress and/or probes, it might be required to open certain networks or ports on the VPN firewall. That is beyond the scope of this document. Please refer to the Wireguard client image for more details on these environment variables. Note The WAIT_FOR_VPN environment variable is specifically implemented by our own qBittorrent image, and it will not work with other container images. image : repository : k8sathome/qbittorrent tag : v4.3.3 pullPolicy : IfNotPresent env : # Our qBittorrent image has a feature that can wait for the VPN to be connected before actually starting the application. # It does this by checking the contents of a file /shared/vpnstatus to contain the string 'connected'. WAIT_FOR_VPN : \"true\" persistence : config : enabled : true emptyDir : true mountPath : /config # This should be enabled so that both the qBittorrent and Wireguard container have access to a shared volume mounted to /shared. # It will be used to communicate between the two containers. shared : enabled : true emptyDir : true mountPath : /shared addons : vpn : enabled : true # This Should be set to `wireguard`. This will set the add-on to use the default settings for Wireguard based connections. type : wireguard # If the podSecurityContext is set to run as a different user, make sure to run the Wireguard container as UID/GID 568. # This is required for it to be able to read certain configuration files. securityContext : runAsUser : 568 runAsGroup : 568 env : # Enable a killswitch that kills all trafic when the VPN is not connected KILLSWITCH : \"true\" # The wireguard configuration file provided by your VPN provider goes here. # # Set AllowedIPs to 0.0.0.0/0 to route all traffic through the VPN. # # Pay close attention to the PostUp and PreDown lines. They must be added if you wish to run a script when the connection # is opened / closed. configFile : |- [Interface] PrivateKey = <my-private-key> Address = <interface address> DNS = <interface DNS server> PostUp = /config/up.sh %i PreDown = /config/down.sh %i [Peer] PublicKey = <my-public-key> AllowedIPs = 0.0.0.0/0 Endpoint = <peer endpoint> # The scripts that get run when the VPN connection opens/closes are defined here. # The default scripts will write a string to represent the current connection state to a file. # Our qBittorrent image has a feature that can wait for this file to contain the word 'connected' before actually starting the application. scripts : up : |- #!/bin/bash echo \"connected\" > /shared/vpnstatus down : |- #!/bin/bash echo \"disconnected\" > /shared/vpnstatus","title":"Example values"},{"location":"our-helm-charts/common-library-add-ons/#openvpn","text":"Similar to the Wireguard VPN, the OpenVPN add-on enables you to force all (or selected) network traffic through a VPN. This example shows how to add an OpenVPN sidecar to our qBittorrent Helm chart . It does not cover all of the configuration possibilities of the OpenVPN client image by @dperson , but should give a good starting point for configuring a similar setup.","title":"OpenVPN"},{"location":"our-helm-charts/common-library-add-ons/#example-values_2","text":"Below is an annotated example values.yaml that will result in a qBittorrent container with all its traffic routed through a VPN. In order to have functioning ingress and/or probes, it might be required to open certain networks or ports on the VPN firewall. That is beyond the scope of this document. Please refer to the OpenVPN client image for more details on these environment variables. Note The WAIT_FOR_VPN environment variable is specifically implemented by our own qBittorrent image, and it will not work with other container images. image : repository : k8sathome/qbittorrent tag : v4.3.3 pullPolicy : IfNotPresent env : # Our qBittorrent image has a feature that can wait for the VPN to be # connected before actually starting the application. # It does this by checking the contents of a file /shared/vpnstatus to # contain the string 'connected'. WAIT_FOR_VPN : \"true\" persistence : config : enabled : true emptyDir : true mountPath : /config # This should be enabled so that both the qBittorrent and OpenVPN container have access to a shared volume mounted to /shared. # It will be used to communicate between the two containers. shared : enabled : true emptyDir : true mountPath : /shared addons : vpn : enabled : true # This Should be set to `openvpn`. This will set the add-on to use the default settings for OpenVPN based connections. type : openvpn openvpn : # This gets read by the Helm chart. The default OpenVPN image reads this and uses it to connect to the VPN provider. auth : | myuser mypassword # If the podSecurityContext is set to run as a different user, make sure to run the OpenVPN container as root. # This is required for it to be able to read certain configuration files. securityContext : runAsGroup : 0 runAsUser : 0 env : # Set this environment variable to 'on' to make sure all traffic gets routed through the VPN container. # Make sure to check the other environment variables for the OpenVPN image to see how you can exclude certain # traffic from these firewall rules. FIREWALL : 'on' # The .ovpn file provided by your VPN provider goes here. # # Any CA / certificate must either be placed inline, or provided through an additionalVolumeMount so that OpenVPN can find it. # # Pay close attention to the last 3 lines in this file. They must be added if you wish to run a script when the connection # is opened / closed. configFile : |- client dev tun proto udp remote my-awesome-vpn-provider.com 995 remote-cert-tls server resolv-retry infinite nobind tls-version-min 1.2 cipher AES-128-GCM compress ncp-disable tun-mtu-extra 32 auth-user-pass <ca> -----BEGIN CERTIFICATE----- MIIDMTCCAhmgAwIBAgIJAKnGGJK6qLqSMA0GCSqGSIb3DQEBCwUAMBQxEjAQBgNV -----END CERTIFICATE----- </ca> script-security 2 up /vpn/up.sh down /vpn/down.sh # The scripts that get run when the VPN connection opens/closes are defined here. # The default scripts will write a string to represent the current connection state to a file. # Our qBittorrent image has a feature that can wait for this file to contain the word 'connected' before actually starting the application. scripts : up : |- #!/bin/bash /etc/openvpn/up.sh echo \"connected\" > /shared/vpnstatus down : |- #!/bin/bash /etc/openvpn/down.sh echo \"disconnected\" > /shared/vpnstatus","title":"Example values"},{"location":"our-helm-charts/common-library/","text":"Common library \u00b6 Most of our application Helm charts consume our Common library Helm chart. Note The Common library chart is not meant to be installed directly, application charts use the Common library as a dependency. Background \u00b6 In Helm 3, their team introduced the concept of a Library chart . A library chart is a type of Helm chart that defines chart primitives or definitions which can be shared by Helm templates in other charts. This allows users to share snippets of code that can be re-used across charts, avoiding repetition and keeping charts DRY. The common library was created because we saw many charts requiring only a few select configuration options in their Helm charts. Note Take one of the many charts like sonarr or nzbget . Each of these charts only require setting service , port , persistence , ingress and image since state and app configuration is handled by the application itself. In order to stay somewhat DRY (Don't Repeat Yourself) and keeping with Helm 3 usage for a Library chart, we saw this pattern and decided it was worth it for us to create a library. This means each one of these app charts has a dependency on what we call the common library. Changelog \u00b6 To view the changelog for the common library see here . Source code \u00b6 The source code for our library chart can be found here .","title":"Common"},{"location":"our-helm-charts/common-library/#common-library","text":"Most of our application Helm charts consume our Common library Helm chart. Note The Common library chart is not meant to be installed directly, application charts use the Common library as a dependency.","title":"Common library"},{"location":"our-helm-charts/common-library/#background","text":"In Helm 3, their team introduced the concept of a Library chart . A library chart is a type of Helm chart that defines chart primitives or definitions which can be shared by Helm templates in other charts. This allows users to share snippets of code that can be re-used across charts, avoiding repetition and keeping charts DRY. The common library was created because we saw many charts requiring only a few select configuration options in their Helm charts. Note Take one of the many charts like sonarr or nzbget . Each of these charts only require setting service , port , persistence , ingress and image since state and app configuration is handled by the application itself. In order to stay somewhat DRY (Don't Repeat Yourself) and keeping with Helm 3 usage for a Library chart, we saw this pattern and decided it was worth it for us to create a library. This means each one of these app charts has a dependency on what we call the common library.","title":"Background"},{"location":"our-helm-charts/common-library/#changelog","text":"To view the changelog for the common library see here .","title":"Changelog"},{"location":"our-helm-charts/common-library/#source-code","text":"The source code for our library chart can be found here .","title":"Source code"},{"location":"our-helm-charts/introduction/","text":"Introduction \u00b6 Helm must be installed to use our charts. Refer to Helm's documentation to get started. Installation \u00b6 helm repo add k8s-at-home https://k8s-at-home.com/charts/ You can then run helm search repo k8s-at-home to see the charts. Charts \u00b6 See Artifact Hub for a complete list.","title":"Introduction"},{"location":"our-helm-charts/introduction/#introduction","text":"Helm must be installed to use our charts. Refer to Helm's documentation to get started.","title":"Introduction"},{"location":"our-helm-charts/introduction/#installation","text":"helm repo add k8s-at-home https://k8s-at-home.com/charts/ You can then run helm search repo k8s-at-home to see the charts.","title":"Installation"},{"location":"our-helm-charts/introduction/#charts","text":"See Artifact Hub for a complete list.","title":"Charts"},{"location":"our-helm-charts/development/creating-a-new-chart/","text":"Creating a new chart \u00b6 Dependencies \u00b6 If you would like to help create new charts using the common library, there's a few tools you will need. helm helm-docs task (optional) Creating a new chart \u00b6 To create a new chart, run the following: # Clone git clone cd charts sh -c \" $( curl --location https://taskfile.dev/install.sh ) \" -- -d -b .bin # Create chart PATH = $PATH : $PWD /.bin task deps:install task chart:create CHART = chart-name # Don't forgot edit some chart informations in charts/chart-name/Chart.yaml and charts/chart-name/values.yaml Second, be sure to checkout the many charts that already use this like qBittorrent , node-red or the many others in this repository. Include this chart as a dependency in your Chart.yaml e.g. # Chart.yaml ... dependencies : - name : common version : 3.0.1 # make sure to use the latest common library version available repository : https://library-charts.k8s-at-home.com ... Values \u00b6 Write a values.yaml with some basic defaults you want to present to the user e.g. # # IMPORTANT NOTE # # This chart inherits from our common library chart. You can check the default values/options here: # https://github.com/k8s-at-home/library-charts/tree/master/charts/stable/common/values.yaml # image : repository : nodered/node-red pullPolicy : IfNotPresent tag : 1.2.5 strategy : type : Recreate # See more environment variables in the node-red documentation # https://nodered.org/docs/getting-started/docker env : {} # TZ: # NODE_OPTIONS: # NODE_RED_ENABLE_PROJECTS: # NODE_RED_ENABLE_SAFE_MODE: # FLOWS: service : port : port : 1880 ingress : enabled : false persistence : data : enabled : false emptyDir : false mountPath : /data If not using a service, set the service.enabled to false . ... service : enabled : false ... Templates \u00b6 Basic \u00b6 In its most basic form a new chart can consist of two simple files in the templates folder. This will automatically render everything, based only on what is (or isn't) present in values.yaml . templates/common.yaml : {{ include \"common.all . }} templates/NOTES.txt : {{ include \"common.notes.defaultNotes\" . }} Advanced \u00b6 Sometimes it is not required to implement additional logic in a chart that you do not wish to expose through settings in values.yaml . For example, when you want to always mount a Secret or configMap as a volume in the Pod. In that case it is also possible to write more advanced template files. templates/common.yaml : {{ /* First Make sure all variables are set and merged properly */ }} {{ - include \"common.values.setup\" . }} {{ /* Append a configMap to the additionalVolumes */ }} {{ - define \"myapp.configmap.volume\" - }} name : myapp-settings configMap : name : {{ template \"common.names.fullname\" . }} -settings {{ - end - }} {{ - $volume : = include \"myapp.configmap.volume\" . | fromYaml - }} {{ - if $volume - }} {{ - $additionalVolumes : = append .Values.additionalVolumes $volume }} {{ - $_ : = set .Values \"additionalVolumes\" (deepCopy $additionalVolumes) - }} {{ - end - }} {{ /* Render the templates */ }} {{ include \"common.all\" . }} An actual example of this can be found in the zigbee2mqtt chart. Testing \u00b6 If testing locally, make sure you update the dependencies with from the chart directory: helm dependency update If making local changes to the common library, the test chart may reference the local development chart: # common-test/Chart.yaml ... dependencies : - name : common version : <new version> repository : file://.../common ... Be sure to lint your chart to check for any errors. # Linting task chart:lint CHART = chart-name task chart:ct-lint CHART = chart-name","title":"Creating a new chart"},{"location":"our-helm-charts/development/creating-a-new-chart/#creating-a-new-chart","text":"","title":"Creating a new chart"},{"location":"our-helm-charts/development/creating-a-new-chart/#dependencies","text":"If you would like to help create new charts using the common library, there's a few tools you will need. helm helm-docs task (optional)","title":"Dependencies"},{"location":"our-helm-charts/development/creating-a-new-chart/#creating-a-new-chart_1","text":"To create a new chart, run the following: # Clone git clone cd charts sh -c \" $( curl --location https://taskfile.dev/install.sh ) \" -- -d -b .bin # Create chart PATH = $PATH : $PWD /.bin task deps:install task chart:create CHART = chart-name # Don't forgot edit some chart informations in charts/chart-name/Chart.yaml and charts/chart-name/values.yaml Second, be sure to checkout the many charts that already use this like qBittorrent , node-red or the many others in this repository. Include this chart as a dependency in your Chart.yaml e.g. # Chart.yaml ... dependencies : - name : common version : 3.0.1 # make sure to use the latest common library version available repository : https://library-charts.k8s-at-home.com ...","title":"Creating a new chart"},{"location":"our-helm-charts/development/creating-a-new-chart/#values","text":"Write a values.yaml with some basic defaults you want to present to the user e.g. # # IMPORTANT NOTE # # This chart inherits from our common library chart. You can check the default values/options here: # https://github.com/k8s-at-home/library-charts/tree/master/charts/stable/common/values.yaml # image : repository : nodered/node-red pullPolicy : IfNotPresent tag : 1.2.5 strategy : type : Recreate # See more environment variables in the node-red documentation # https://nodered.org/docs/getting-started/docker env : {} # TZ: # NODE_OPTIONS: # NODE_RED_ENABLE_PROJECTS: # NODE_RED_ENABLE_SAFE_MODE: # FLOWS: service : port : port : 1880 ingress : enabled : false persistence : data : enabled : false emptyDir : false mountPath : /data If not using a service, set the service.enabled to false . ... service : enabled : false ...","title":"Values"},{"location":"our-helm-charts/development/creating-a-new-chart/#templates","text":"","title":"Templates"},{"location":"our-helm-charts/development/creating-a-new-chart/#basic","text":"In its most basic form a new chart can consist of two simple files in the templates folder. This will automatically render everything, based only on what is (or isn't) present in values.yaml . templates/common.yaml : {{ include \"common.all . }} templates/NOTES.txt : {{ include \"common.notes.defaultNotes\" . }}","title":"Basic"},{"location":"our-helm-charts/development/creating-a-new-chart/#advanced","text":"Sometimes it is not required to implement additional logic in a chart that you do not wish to expose through settings in values.yaml . For example, when you want to always mount a Secret or configMap as a volume in the Pod. In that case it is also possible to write more advanced template files. templates/common.yaml : {{ /* First Make sure all variables are set and merged properly */ }} {{ - include \"common.values.setup\" . }} {{ /* Append a configMap to the additionalVolumes */ }} {{ - define \"myapp.configmap.volume\" - }} name : myapp-settings configMap : name : {{ template \"common.names.fullname\" . }} -settings {{ - end - }} {{ - $volume : = include \"myapp.configmap.volume\" . | fromYaml - }} {{ - if $volume - }} {{ - $additionalVolumes : = append .Values.additionalVolumes $volume }} {{ - $_ : = set .Values \"additionalVolumes\" (deepCopy $additionalVolumes) - }} {{ - end - }} {{ /* Render the templates */ }} {{ include \"common.all\" . }} An actual example of this can be found in the zigbee2mqtt chart.","title":"Advanced"},{"location":"our-helm-charts/development/creating-a-new-chart/#testing","text":"If testing locally, make sure you update the dependencies with from the chart directory: helm dependency update If making local changes to the common library, the test chart may reference the local development chart: # common-test/Chart.yaml ... dependencies : - name : common version : <new version> repository : file://.../common ... Be sure to lint your chart to check for any errors. # Linting task chart:lint CHART = chart-name task chart:ct-lint CHART = chart-name","title":"Testing"},{"location":"our-helm-charts/development/databases/","text":"Databases \u00b6 Databases from other repositories can be added to charts as dependencies. The databases are only installed if the <db name>.enabled key is set to true. See home-assistant for reference. Chart.yaml \u00b6 Add the following entries to Chart.yaml under the dependencies section. ... dependencies : - name : postgresql version : <chart version> repository : https://charts.bitnami.com/bitnami condition : postgresql.enabled - name : mariadb version : <chart version> repository : https://charts.bitnami.com/bitnami condition : mariadb.enabled - name : influxdb version : <chart version> repository : https://charts.bitnami.com/bitnami condition : influxdb.enabled values.yaml \u00b6 Update the values.yaml with the following. Refer the respective database chart values.yaml for additional values. MariaDB \u00b6 ... mariadb : enabled : false architecture : standalone auth : database : <chart name> username : <chart name> password : <chart password> rootPassword : home-assistantrootpass primary : persistence : enabled : false Postgres \u00b6 ... postgresql : enabled : false postgresqlUsername : <chart name> postgresqlPassword : <chart password> postgresqlDatabase : <chart name> persistence : enabled : false InfluxDB \u00b6 ... influxdb : enabled : false architecture : standalone database : <chart name> authEnabled : false persistence : enabled : false","title":"Databases"},{"location":"our-helm-charts/development/databases/#databases","text":"Databases from other repositories can be added to charts as dependencies. The databases are only installed if the <db name>.enabled key is set to true. See home-assistant for reference.","title":"Databases"},{"location":"our-helm-charts/development/databases/#chartyaml","text":"Add the following entries to Chart.yaml under the dependencies section. ... dependencies : - name : postgresql version : <chart version> repository : https://charts.bitnami.com/bitnami condition : postgresql.enabled - name : mariadb version : <chart version> repository : https://charts.bitnami.com/bitnami condition : mariadb.enabled - name : influxdb version : <chart version> repository : https://charts.bitnami.com/bitnami condition : influxdb.enabled","title":"Chart.yaml"},{"location":"our-helm-charts/development/databases/#valuesyaml","text":"Update the values.yaml with the following. Refer the respective database chart values.yaml for additional values.","title":"values.yaml"},{"location":"our-helm-charts/development/databases/#mariadb","text":"... mariadb : enabled : false architecture : standalone auth : database : <chart name> username : <chart name> password : <chart password> rootPassword : home-assistantrootpass primary : persistence : enabled : false","title":"MariaDB"},{"location":"our-helm-charts/development/databases/#postgres","text":"... postgresql : enabled : false postgresqlUsername : <chart name> postgresqlPassword : <chart password> postgresqlDatabase : <chart name> persistence : enabled : false","title":"Postgres"},{"location":"our-helm-charts/development/databases/#influxdb","text":"... influxdb : enabled : false architecture : standalone database : <chart name> authEnabled : false persistence : enabled : false","title":"InfluxDB"},{"location":"our-helm-charts/development/unit-tests/","text":"Unit tests \u00b6 We unit test our common library, while it isn't near complete coverage but it does offer some basic checks. Running these tests can be done any way you like. In this document we describe a number of approaches. Directly on your development machine \u00b6 First set up the environment: export RUBYJQ_USE_SYSTEM_LIBRARIES = 1 bundle install Run the tests: bundle exec m -r test/charts Using Visual Studio Code \u00b6 Our repo comes with a Visual Studio Code development container definition and launch.json that allow you to quickly set up an environment in which you can run the tests. Prerequisites \u00b6 Visual Studio Code is installed. Docker is installed and running. The \"Remote - Containers\" extension is installed and enabled in Visual Studio Code. For more details, please refer to the official documentation . Running tests \u00b6 Once Visual Studio Code is set up, and you open the charts workspace, you will see a popup asking if you wish to re-open the workspace in a development container: Select the option that you prefer. The workspace will be reopened and a Dockerized workspace will be built. You can now use Visual Studio Code as normal. To run or debug the unit tests, click the \"Run\" button on the left sidebar and select the desired configuration: UnitTest - active spec file only : This configuration will try to run the currently opened test file. Note: Make sure that you have opened a valid test file ( .rb files in the test/charts folder), or this will not work. UnitTest - all spec files : This configuration will run the all test files in the test/charts folder. Next, press the green \"Play\" icon. This will start the tests show the outcome in a terminal window. Using a local Docker container \u00b6 The Visual Studio Code development container can also be leveraged without using Visual Studio Code. Prerequisites \u00b6 Docker is installed and running. You have the charts repo root folder opened in your shell of choice. The commands in this article assume you are running a Bash-compatible shell. Running tests \u00b6 The first step is to build the development container image containing the required tools. This step only needs to be done once. To build the container, run this command in your shell: docker build -t k8s-at-home/charts-unit-test -f .devcontainer/Dockerfile . When you wish to run the tests, run this command in your shell: docker run --rm -it -v $( pwd ) :/charts --entrypoint \"/bin/bash\" -w /charts k8s-at-home/charts-unit-test -l -c \"bundle exec m -r ./test/charts\" This will create a container with the charts repo root folder mounted to /charts and execute all the test files in the test/charts folder. Output \u00b6 A successful test will output something like the following... Started with run options --seed 52955 common-test::statefulset volumeClaimTemplates can set values for volumeClaimTemplates PASS (0.16s) volumeClaimTemplates should be empty by default PASS (0.06s) common-test::ports settings targetPort can be overridden PASS (0.17s) port name can be overridden PASS (0.17s) defaults to name \"http\" on port 8080 PASS (0.16s) targetPort cannot be a named port PASS (0.05s) common-test::pod replicas defaults to 1 PASS (0.08s) accepts integer as value PASS (0.08s) common-test::Environment settings Check no environment variables PASS (0.05s) set \"valueFrom\" environment variables PASS (0.11s) set \"static\" and \"Dynamic/Tpl\" environment variables PASS (0.15s) set \"Dynamic/Tpl\" environment variables PASS (0.11s) set \"static\" environment variables PASS (0.10s) common-test::ingress ingress with hosts PASS (0.10s) should be disabled when ingress.enabled: false PASS (0.06s) ingress with hosts template is evaluated PASS (0.11s) ingress with hosts and tls PASS (0.15s) ingress with hosts and tls templates is evaluated PASS (0.16s) should be enabled when ingress.enabled: true PASS (0.06s) common-test::controller type accepts \"daemonset\" PASS (0.06s) accepts \"statefulset\" PASS (0.06s) defaults to \"Deployment\" PASS (0.06s) Finished in 2.26077s 22 tests, 59 assertions, 0 failures, 0 errors, 0 skips","title":"Unit tests"},{"location":"our-helm-charts/development/unit-tests/#unit-tests","text":"We unit test our common library, while it isn't near complete coverage but it does offer some basic checks. Running these tests can be done any way you like. In this document we describe a number of approaches.","title":"Unit tests"},{"location":"our-helm-charts/development/unit-tests/#directly-on-your-development-machine","text":"First set up the environment: export RUBYJQ_USE_SYSTEM_LIBRARIES = 1 bundle install Run the tests: bundle exec m -r test/charts","title":"Directly on your development machine"},{"location":"our-helm-charts/development/unit-tests/#using-visual-studio-code","text":"Our repo comes with a Visual Studio Code development container definition and launch.json that allow you to quickly set up an environment in which you can run the tests.","title":"Using Visual Studio Code"},{"location":"our-helm-charts/development/unit-tests/#prerequisites","text":"Visual Studio Code is installed. Docker is installed and running. The \"Remote - Containers\" extension is installed and enabled in Visual Studio Code. For more details, please refer to the official documentation .","title":"Prerequisites"},{"location":"our-helm-charts/development/unit-tests/#running-tests","text":"Once Visual Studio Code is set up, and you open the charts workspace, you will see a popup asking if you wish to re-open the workspace in a development container: Select the option that you prefer. The workspace will be reopened and a Dockerized workspace will be built. You can now use Visual Studio Code as normal. To run or debug the unit tests, click the \"Run\" button on the left sidebar and select the desired configuration: UnitTest - active spec file only : This configuration will try to run the currently opened test file. Note: Make sure that you have opened a valid test file ( .rb files in the test/charts folder), or this will not work. UnitTest - all spec files : This configuration will run the all test files in the test/charts folder. Next, press the green \"Play\" icon. This will start the tests show the outcome in a terminal window.","title":"Running tests"},{"location":"our-helm-charts/development/unit-tests/#using-a-local-docker-container","text":"The Visual Studio Code development container can also be leveraged without using Visual Studio Code.","title":"Using a local Docker container"},{"location":"our-helm-charts/development/unit-tests/#prerequisites_1","text":"Docker is installed and running. You have the charts repo root folder opened in your shell of choice. The commands in this article assume you are running a Bash-compatible shell.","title":"Prerequisites"},{"location":"our-helm-charts/development/unit-tests/#running-tests_1","text":"The first step is to build the development container image containing the required tools. This step only needs to be done once. To build the container, run this command in your shell: docker build -t k8s-at-home/charts-unit-test -f .devcontainer/Dockerfile . When you wish to run the tests, run this command in your shell: docker run --rm -it -v $( pwd ) :/charts --entrypoint \"/bin/bash\" -w /charts k8s-at-home/charts-unit-test -l -c \"bundle exec m -r ./test/charts\" This will create a container with the charts repo root folder mounted to /charts and execute all the test files in the test/charts folder.","title":"Running tests"},{"location":"our-helm-charts/development/unit-tests/#output","text":"A successful test will output something like the following... Started with run options --seed 52955 common-test::statefulset volumeClaimTemplates can set values for volumeClaimTemplates PASS (0.16s) volumeClaimTemplates should be empty by default PASS (0.06s) common-test::ports settings targetPort can be overridden PASS (0.17s) port name can be overridden PASS (0.17s) defaults to name \"http\" on port 8080 PASS (0.16s) targetPort cannot be a named port PASS (0.05s) common-test::pod replicas defaults to 1 PASS (0.08s) accepts integer as value PASS (0.08s) common-test::Environment settings Check no environment variables PASS (0.05s) set \"valueFrom\" environment variables PASS (0.11s) set \"static\" and \"Dynamic/Tpl\" environment variables PASS (0.15s) set \"Dynamic/Tpl\" environment variables PASS (0.11s) set \"static\" environment variables PASS (0.10s) common-test::ingress ingress with hosts PASS (0.10s) should be disabled when ingress.enabled: false PASS (0.06s) ingress with hosts template is evaluated PASS (0.11s) ingress with hosts and tls PASS (0.15s) ingress with hosts and tls templates is evaluated PASS (0.16s) should be enabled when ingress.enabled: true PASS (0.06s) common-test::controller type accepts \"daemonset\" PASS (0.06s) accepts \"statefulset\" PASS (0.06s) defaults to \"Deployment\" PASS (0.06s) Finished in 2.26077s 22 tests, 59 assertions, 0 failures, 0 errors, 0 skips","title":"Output"},{"location":"support/code-of-conduct/","text":"Contributor Covenant Code of Conduct \u00b6 Our Pledge \u00b6 We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards \u00b6 Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities \u00b6 Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope \u00b6 This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at Devin buhl devin.kray@gmail.com or Jeff Billimek jeff@billimek.com . All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines \u00b6 Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction \u00b6 Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning \u00b6 Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban \u00b6 Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban \u00b6 Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Code of Conduct"},{"location":"support/code-of-conduct/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"support/code-of-conduct/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"support/code-of-conduct/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"support/code-of-conduct/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"support/code-of-conduct/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"support/code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at Devin buhl devin.kray@gmail.com or Jeff Billimek jeff@billimek.com . All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"support/code-of-conduct/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"support/code-of-conduct/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"support/code-of-conduct/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"support/code-of-conduct/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"support/code-of-conduct/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"support/code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"support/community/","text":"Community \u00b6 We have a few outlets for getting community support with our projects: Issues \u00b6 If you encounter an issue when using our charts or container images, please add it to their respective GitHub Issues tracker. Please make sure you use the provided issue templates so that can better understand your issue as well as duplicate it on our end! Forum \u00b6 We use GitHub Discussions to provide a forum to hold discussions among the community. Everything that is not an issue but is related to k8s@home can be discussed here: use-cases, requests for help and suggestions, discussions on the future of projects, and other similar topics. Chat \u00b6 We use Discord as a chat solution for allowing both k8s@home users and developers to interact in real time. Click here for an invitation.","title":"Community"},{"location":"support/community/#community","text":"We have a few outlets for getting community support with our projects:","title":"Community"},{"location":"support/community/#issues","text":"If you encounter an issue when using our charts or container images, please add it to their respective GitHub Issues tracker. Please make sure you use the provided issue templates so that can better understand your issue as well as duplicate it on our end!","title":"Issues"},{"location":"support/community/#forum","text":"We use GitHub Discussions to provide a forum to hold discussions among the community. Everything that is not an issue but is related to k8s@home can be discussed here: use-cases, requests for help and suggestions, discussions on the future of projects, and other similar topics.","title":"Forum"},{"location":"support/community/#chat","text":"We use Discord as a chat solution for allowing both k8s@home users and developers to interact in real time. Click here for an invitation.","title":"Chat"},{"location":"support/faq/","text":"Frequently Asked Questions \u00b6 Why aren't the charts updated with each image release? \u00b6 k8s@home feels that it is the responsibility of the person deploying the chart to ensure that the most up to date image is being deployed as well as keeping the deployed images up to date. Keeping images would be a full time job due to the frequent code changes and so the the k8s@home community would rather spend their time implementing new features and charts for everyone to use.","title":"FAQ"},{"location":"support/faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"support/faq/#why-arent-the-charts-updated-with-each-image-release","text":"k8s@home feels that it is the responsibility of the person deploying the chart to ensure that the most up to date image is being deployed as well as keeping the deployed images up to date. Keeping images would be a full time job due to the frequent code changes and so the the k8s@home community would rather spend their time implementing new features and charts for everyone to use.","title":"Why aren't the charts updated with each image release?"}]}